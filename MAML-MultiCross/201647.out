nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2020 NVIDIA Corporation
Built on Mon_Oct_12_20:09:46_PDT_2020
Cuda compilation tools, release 11.1, V11.1.105
Build cuda_11.1.TC455_06.29190527_0
----------------------------------
Mon Dec  5 08:13:50 2022       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Tesla V100-SXM2...  Off  | 00000000:3A:00.0 Off |                    0 |
| N/A   35C    P0    54W / 300W |      0MiB / 32510MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
batch_size 4 <class 'int'>
train_datasets_ids 11,12 <class 'str'>
dev_dataset_id 3 <class 'str'>
test_dataset_id 14 <class 'str'>
reset_stored_filepaths False <class 'bool'>
num_of_gpus 1 <class 'int'>
indexes_of_folders_indicating_class [-2, -3] <class 'list'>
train_val_test_split [0.73982737361, 0.26, 0.13008631319] <class 'list'>
samples_per_iter 1 <class 'int'>
seed 104 <class 'int'>
gpu_to_use 0 <class 'int'>
num_dataprovider_workers 4 <class 'int'>
dataset_name omniglot_dataset <class 'str'>
dataset_path /home/mrvoh/Desktop/datasets/multi_task_class_descr/datasets/omniglot_dataset
dataset_path /home/mrvoh/Desktop/datasets/multi_task_class_descr/datasets/omniglot_dataset <class 'str'>
pretrained_weights bert-base-multilingual-cased <class 'str'>
reset_stored_paths False <class 'bool'>
experiment_name all_experiments-threewayprotomaml/1/ <class 'str'>
continue_from_epoch latest <class 'str'>
num_target_samples 32 <class 'int'>
second_order False <class 'bool'>
first_order_to_second_order_epoch 50 <class 'int'>
total_epochs 100 <class 'int'>
total_iter_per_epoch 100 <class 'int'>
total_epochs_before_pause 50 <class 'int'>
per_step_layer_norm_weights True <class 'bool'>
evalute_on_test_set_only False <class 'bool'>
num_evaluation_tasks 50 <class 'int'>

learnable_per_layer_per_step_inner_loop_learning_rate True <class 'bool'>
enable_inner_loop_optimizable_ln_params None <class 'NoneType'>
init_inner_loop_learning_rate 5e-05 <class 'float'>
min_learning_rate 1e-06 <class 'float'>
meta_learning_rate 3e-05 <class 'float'>
meta_inner_optimizer_learning_rate 6e-05 <class 'float'>
num_classes_per_set 3 <class 'int'>
number_of_training_steps_per_iter 5 <class 'int'>
number_of_evaluation_steps_per_iter 1 <class 'int'>
num_samples_per_class 32 <class 'int'>
eval_using_full_task_set True <class 'bool'>
split_support_and_query True <class 'bool'>
sample_task_to_size_ratio False <class 'bool'>
enable_inner_loop_optimizable_bn_params True <class 'bool'>
shuffle_labels True <class 'bool'>
num_evaluation_seeds 5 <class 'int'>
meta_update_method threewayprotomaml <class 'str'>
init_class_head_lr_multiplier 10 <class 'int'>
gold_label_task_sample_ratio 0 <class 'int'>
num_freeze_epochs 0 <class 'int'>
patience 10 <class 'int'>
train_seed 42 <class 'int'>
val_seed 0 <class 'int'>
evaluate_on_test_set_only False <class 'bool'>
num_start_epochs 0 <class 'int'>
protomaml_do_centralize True <class 'bool'>
val_using_cross_entropy False <class 'bool'>
temperature 1 <class 'int'>
meta_loss ce <class 'str'>
gold_label_tasks [] <class 'list'>
scale_losses False <class 'bool'>
use_swa False <class 'bool'>
num_swa 5 <class 'int'>
use_majority_vote False <class 'bool'>
num_majority_votes 5 <class 'int'>
majority_vote_at_test_only False <class 'bool'>
use_label_guided_learning False <class 'bool'>
use_uncertainty_task_weighting False <class 'bool'>
use_triplet_loss False <class 'bool'>
triplet_loss_in_inner_loop False <class 'bool'>
use_cosine_distance False <class 'bool'>
triplet_loss_margin 0.5 <class 'float'>
triplet_loss_lambda 1.0 <class 'float'>
use_consistency_loss False <class 'bool'>
use_multilingual_consistency_loss False <class 'bool'>
consistency_loss_lambda 1.0 <class 'float'>
consistency_loss_beta 1.0 <class 'float'>
use_convex_feature_space_loss False <class 'bool'>
convex_feature_space_loss_in_inner_loop False <class 'bool'>
convex_feature_space_loss_lambda 1.0 <class 'float'>
convex_feature_space_loss_nr_steps 10 <class 'int'>
use_adapter False <class 'bool'>
proportion_intra_task_sampling 0.85 <class 'float'>
variable_nr_classes_and_samples False <class 'bool'>
finetune_task_name val/RCV2_ja_gt <class 'str'>
num_finetune_epochs 1 <class 'int'>
eval_every_finetune 1 <class 'int'>
finetune_base_model False <class 'bool'>
percentage_train_finetune 0.95 <class 'float'>
factory_finetune False <class 'bool'>
finetune_on_cpu False <class 'bool'>
factory_finetune_tasks_path finetune_tasks.txt <class 'str'>
finetune_out_path finetune_log_old.json <class 'str'>
bootstrap_finetune False <class 'bool'>
num_bootstrap_seeds 5 <class 'int'>
device: %s cuda
Warning! Parameter classifier.dense.weight not loaded from pre-trained checkpoint.
Warning! Parameter classifier.dense.bias not loaded from pre-trained checkpoint.
Warning! Parameter classifier.out_proj.weight not loaded from pre-trained checkpoint.
Warning! Parameter classifier.out_proj.bias not loaded from pre-trained checkpoint.
5e-05
Ranger optimizer loaded. 
Gradient Centralization usage = True
GC applied to both conv and fc layers
Doubling the amount of samples in the support set to split prototype creation and fast adapation...
attempting to find existing checkpoint
data {'train': 6, 'val': 3, 'test': 3}
train_seed 121959, val_seed: 985773, at start time
6100 10000
self.epoch chosen to evaluate on testing set: 61
Loading best model for evaluation..
Evaluating model of epoch: 53
Evaluating ar_test with seed 42...
Evaluating model...
Accuracy 0.6190476190476191
Accuracy: 0.51190
Precision: 0.47042
Recall: 0.35185
F1: 0.39766
Evaluating ar_test with seed 43...
Evaluating model...
Accuracy 0.5833333333333334
Accuracy: 0.51190
Precision: 0.43402
Recall: 0.34028
F1: 0.38081
Evaluating ar_test with seed 44...
Evaluating model...
Accuracy 0.5119047619047619
Accuracy: 0.35714
Precision: 0.37120
Recall: 0.24769
F1: 0.29122
Evaluating ar_test with seed 45...
Evaluating model...
Accuracy 0.6428571428571429
Accuracy: 0.53571
Precision: 0.47677
Recall: 0.36343
F1: 0.41152
Evaluating ar_test with seed 46...
Evaluating model...
Accuracy 0.7142857142857143
Accuracy: 0.54762
Precision: 0.52859
Recall: 0.38194
F1: 0.43307
New best performance for task ar_test
test_accuracy_mean: 0.61429
test_accuracy_std: 0.06675
test_loss_mean: 1.39554
test_loss_std: 0.56581
test_ce_loss_mean: 1.39554
test_ce_loss_std: 0.56581
----------------------------------
batch_size 4 <class 'int'>
train_datasets_ids 11,12 <class 'str'>
dev_dataset_id 3 <class 'str'>
test_dataset_id 14 <class 'str'>
reset_stored_filepaths False <class 'bool'>
num_of_gpus 1 <class 'int'>
indexes_of_folders_indicating_class [-2, -3] <class 'list'>
train_val_test_split [0.73982737361, 0.26, 0.13008631319] <class 'list'>
samples_per_iter 1 <class 'int'>
seed 104 <class 'int'>
gpu_to_use 0 <class 'int'>
num_dataprovider_workers 4 <class 'int'>
dataset_name omniglot_dataset <class 'str'>
dataset_path /home/mrvoh/Desktop/datasets/multi_task_class_descr/datasets/omniglot_dataset
dataset_path /home/mrvoh/Desktop/datasets/multi_task_class_descr/datasets/omniglot_dataset <class 'str'>
pretrained_weights bert-base-multilingual-cased <class 'str'>
reset_stored_paths False <class 'bool'>
experiment_name all_experiments-threewayprotomaml/2/ <class 'str'>
continue_from_epoch latest <class 'str'>
num_target_samples 32 <class 'int'>
second_order False <class 'bool'>
first_order_to_second_order_epoch 50 <class 'int'>
total_epochs 100 <class 'int'>
total_iter_per_epoch 100 <class 'int'>
total_epochs_before_pause 50 <class 'int'>
per_step_layer_norm_weights True <class 'bool'>
evalute_on_test_set_only False <class 'bool'>
num_evaluation_tasks 50 <class 'int'>

learnable_per_layer_per_step_inner_loop_learning_rate True <class 'bool'>
enable_inner_loop_optimizable_ln_params None <class 'NoneType'>
init_inner_loop_learning_rate 5e-05 <class 'float'>
min_learning_rate 1e-06 <class 'float'>
meta_learning_rate 3e-05 <class 'float'>
meta_inner_optimizer_learning_rate 6e-05 <class 'float'>
num_classes_per_set 3 <class 'int'>
number_of_training_steps_per_iter 5 <class 'int'>
number_of_evaluation_steps_per_iter 1 <class 'int'>
num_samples_per_class 32 <class 'int'>
eval_using_full_task_set True <class 'bool'>
split_support_and_query True <class 'bool'>
sample_task_to_size_ratio False <class 'bool'>
enable_inner_loop_optimizable_bn_params True <class 'bool'>
shuffle_labels True <class 'bool'>
num_evaluation_seeds 5 <class 'int'>
meta_update_method threewayprotomaml <class 'str'>
init_class_head_lr_multiplier 10 <class 'int'>
gold_label_task_sample_ratio 0 <class 'int'>
num_freeze_epochs 0 <class 'int'>
patience 10 <class 'int'>
train_seed 42 <class 'int'>
val_seed 0 <class 'int'>
evaluate_on_test_set_only False <class 'bool'>
num_start_epochs 0 <class 'int'>
protomaml_do_centralize True <class 'bool'>
val_using_cross_entropy False <class 'bool'>
temperature 1 <class 'int'>
meta_loss ce <class 'str'>
gold_label_tasks [] <class 'list'>
scale_losses False <class 'bool'>
use_swa False <class 'bool'>
num_swa 5 <class 'int'>
use_majority_vote False <class 'bool'>
num_majority_votes 5 <class 'int'>
majority_vote_at_test_only False <class 'bool'>
use_label_guided_learning False <class 'bool'>
use_uncertainty_task_weighting False <class 'bool'>
use_triplet_loss False <class 'bool'>
triplet_loss_in_inner_loop False <class 'bool'>
use_cosine_distance False <class 'bool'>
triplet_loss_margin 0.5 <class 'float'>
triplet_loss_lambda 1.0 <class 'float'>
use_consistency_loss False <class 'bool'>
use_multilingual_consistency_loss False <class 'bool'>
consistency_loss_lambda 1.0 <class 'float'>
consistency_loss_beta 1.0 <class 'float'>
use_convex_feature_space_loss False <class 'bool'>
convex_feature_space_loss_in_inner_loop False <class 'bool'>
convex_feature_space_loss_lambda 1.0 <class 'float'>
convex_feature_space_loss_nr_steps 10 <class 'int'>
use_adapter False <class 'bool'>
proportion_intra_task_sampling 0.85 <class 'float'>
variable_nr_classes_and_samples False <class 'bool'>
finetune_task_name val/RCV2_ja_gt <class 'str'>
num_finetune_epochs 1 <class 'int'>
eval_every_finetune 1 <class 'int'>
finetune_base_model False <class 'bool'>
percentage_train_finetune 0.95 <class 'float'>
factory_finetune False <class 'bool'>
finetune_on_cpu False <class 'bool'>
factory_finetune_tasks_path finetune_tasks.txt <class 'str'>
finetune_out_path finetune_log_old.json <class 'str'>
bootstrap_finetune False <class 'bool'>
num_bootstrap_seeds 5 <class 'int'>
device: %s cuda
Warning! Parameter classifier.dense.weight not loaded from pre-trained checkpoint.
Warning! Parameter classifier.dense.bias not loaded from pre-trained checkpoint.
Warning! Parameter classifier.out_proj.weight not loaded from pre-trained checkpoint.
Warning! Parameter classifier.out_proj.bias not loaded from pre-trained checkpoint.
5e-05
Ranger optimizer loaded. 
Gradient Centralization usage = True
GC applied to both conv and fc layers
Doubling the amount of samples in the support set to split prototype creation and fast adapation...
attempting to find existing checkpoint
data {'train': 6, 'val': 3, 'test': 3}
train_seed 121959, val_seed: 985773, at start time
6100 10000
self.epoch chosen to evaluate on testing set: 61
Loading best model for evaluation..
Evaluating model of epoch: 53
Evaluating ar_test with seed 42...
Evaluating model...
Accuracy 0.5595238095238095
Accuracy: 0.51190
Precision: 0.40408
Recall: 0.34954
F1: 0.37164
Evaluating ar_test with seed 43...
Evaluating model...
Accuracy 0.5714285714285714
Accuracy: 0.44048
Precision: 0.42493
Recall: 0.30324
F1: 0.35012
Evaluating ar_test with seed 44...
Evaluating model...
Accuracy 0.5714285714285714
Accuracy: 0.59524
Precision: 0.43473
Recall: 0.40509
F1: 0.41486
Evaluating ar_test with seed 45...
Evaluating model...
Accuracy 0.6071428571428571
Accuracy: 0.47619
Precision: 0.45934
Recall: 0.31713
F1: 0.37463
Evaluating ar_test with seed 46...
Evaluating model...
Accuracy 0.5238095238095238
Accuracy: 0.45238
Precision: 0.37708
Recall: 0.30324
F1: 0.33534
New best performance for task ar_test
test_accuracy_mean: 0.56667
test_accuracy_std: 0.02673
test_loss_mean: 1.50489
test_loss_std: 0.23258
test_ce_loss_mean: 1.50489
test_ce_loss_std: 0.23258
----------------------------------
batch_size 4 <class 'int'>
train_datasets_ids 11,12 <class 'str'>
dev_dataset_id 3 <class 'str'>
test_dataset_id 14 <class 'str'>
reset_stored_filepaths False <class 'bool'>
num_of_gpus 1 <class 'int'>
indexes_of_folders_indicating_class [-2, -3] <class 'list'>
train_val_test_split [0.73982737361, 0.26, 0.13008631319] <class 'list'>
samples_per_iter 1 <class 'int'>
seed 104 <class 'int'>
gpu_to_use 0 <class 'int'>
num_dataprovider_workers 4 <class 'int'>
dataset_name omniglot_dataset <class 'str'>
dataset_path /home/mrvoh/Desktop/datasets/multi_task_class_descr/datasets/omniglot_dataset
dataset_path /home/mrvoh/Desktop/datasets/multi_task_class_descr/datasets/omniglot_dataset <class 'str'>
pretrained_weights bert-base-multilingual-cased <class 'str'>
reset_stored_paths False <class 'bool'>
experiment_name all_experiments-threewayprotomaml/3/ <class 'str'>
continue_from_epoch latest <class 'str'>
num_target_samples 32 <class 'int'>
second_order False <class 'bool'>
first_order_to_second_order_epoch 50 <class 'int'>
total_epochs 100 <class 'int'>
total_iter_per_epoch 100 <class 'int'>
total_epochs_before_pause 50 <class 'int'>
per_step_layer_norm_weights True <class 'bool'>
evalute_on_test_set_only False <class 'bool'>
num_evaluation_tasks 50 <class 'int'>

learnable_per_layer_per_step_inner_loop_learning_rate True <class 'bool'>
enable_inner_loop_optimizable_ln_params None <class 'NoneType'>
init_inner_loop_learning_rate 5e-05 <class 'float'>
min_learning_rate 1e-06 <class 'float'>
meta_learning_rate 3e-05 <class 'float'>
meta_inner_optimizer_learning_rate 6e-05 <class 'float'>
num_classes_per_set 3 <class 'int'>
number_of_training_steps_per_iter 5 <class 'int'>
number_of_evaluation_steps_per_iter 1 <class 'int'>
num_samples_per_class 32 <class 'int'>
eval_using_full_task_set True <class 'bool'>
split_support_and_query True <class 'bool'>
sample_task_to_size_ratio False <class 'bool'>
enable_inner_loop_optimizable_bn_params True <class 'bool'>
shuffle_labels True <class 'bool'>
num_evaluation_seeds 5 <class 'int'>
meta_update_method threewayprotomaml <class 'str'>
init_class_head_lr_multiplier 10 <class 'int'>
gold_label_task_sample_ratio 0 <class 'int'>
num_freeze_epochs 0 <class 'int'>
patience 10 <class 'int'>
train_seed 42 <class 'int'>
val_seed 0 <class 'int'>
evaluate_on_test_set_only False <class 'bool'>
num_start_epochs 0 <class 'int'>
protomaml_do_centralize True <class 'bool'>
val_using_cross_entropy False <class 'bool'>
temperature 1 <class 'int'>
meta_loss ce <class 'str'>
gold_label_tasks [] <class 'list'>
scale_losses False <class 'bool'>
use_swa False <class 'bool'>
num_swa 5 <class 'int'>
use_majority_vote False <class 'bool'>
num_majority_votes 5 <class 'int'>
majority_vote_at_test_only False <class 'bool'>
use_label_guided_learning False <class 'bool'>
use_uncertainty_task_weighting False <class 'bool'>
use_triplet_loss False <class 'bool'>
triplet_loss_in_inner_loop False <class 'bool'>
use_cosine_distance False <class 'bool'>
triplet_loss_margin 0.5 <class 'float'>
triplet_loss_lambda 1.0 <class 'float'>
use_consistency_loss False <class 'bool'>
use_multilingual_consistency_loss False <class 'bool'>
consistency_loss_lambda 1.0 <class 'float'>
consistency_loss_beta 1.0 <class 'float'>
use_convex_feature_space_loss False <class 'bool'>
convex_feature_space_loss_in_inner_loop False <class 'bool'>
convex_feature_space_loss_lambda 1.0 <class 'float'>
convex_feature_space_loss_nr_steps 10 <class 'int'>
use_adapter False <class 'bool'>
proportion_intra_task_sampling 0.85 <class 'float'>
variable_nr_classes_and_samples False <class 'bool'>
finetune_task_name val/RCV2_ja_gt <class 'str'>
num_finetune_epochs 1 <class 'int'>
eval_every_finetune 1 <class 'int'>
finetune_base_model False <class 'bool'>
percentage_train_finetune 0.95 <class 'float'>
factory_finetune False <class 'bool'>
finetune_on_cpu False <class 'bool'>
factory_finetune_tasks_path finetune_tasks.txt <class 'str'>
finetune_out_path finetune_log_old.json <class 'str'>
bootstrap_finetune False <class 'bool'>
num_bootstrap_seeds 5 <class 'int'>
device: %s cuda
Warning! Parameter classifier.dense.weight not loaded from pre-trained checkpoint.
Warning! Parameter classifier.dense.bias not loaded from pre-trained checkpoint.
Warning! Parameter classifier.out_proj.weight not loaded from pre-trained checkpoint.
Warning! Parameter classifier.out_proj.bias not loaded from pre-trained checkpoint.
5e-05
Ranger optimizer loaded. 
Gradient Centralization usage = True
GC applied to both conv and fc layers
Doubling the amount of samples in the support set to split prototype creation and fast adapation...
attempting to find existing checkpoint
data {'train': 6, 'val': 3, 'test': 3}
train_seed 121959, val_seed: 985773, at start time
6100 10000
self.epoch chosen to evaluate on testing set: 61
Loading best model for evaluation..
Evaluating model of epoch: 50
Evaluating ar_test with seed 42...
Evaluating model...
Accuracy 0.5714285714285714
Accuracy: 0.44048
Precision: 0.44771
Recall: 0.31019
F1: 0.35431
Evaluating ar_test with seed 43...
Evaluating model...
Accuracy 0.6428571428571429
Accuracy: 0.59524
Precision: 0.47807
Recall: 0.40278
F1: 0.43684
Evaluating ar_test with seed 44...
Evaluating model...
Accuracy 0.4166666666666667
Accuracy: 0.32143
Precision: 0.33838
Recall: 0.22685
F1: 0.26229
Evaluating ar_test with seed 45...
Evaluating model...
Accuracy 0.6428571428571429
Accuracy: 0.50000
Precision: 0.43793
Recall: 0.34028
F1: 0.38179
Evaluating ar_test with seed 46...
Evaluating model...
Accuracy 0.5952380952380952
Accuracy: 0.44048
Precision: 0.44667
Recall: 0.30556
F1: 0.35824
New best performance for task ar_test
test_accuracy_mean: 0.57381
test_accuracy_std: 0.08330
test_loss_mean: 1.44148
test_loss_std: 0.52191
test_ce_loss_mean: 1.44148
test_ce_loss_std: 0.52191
----------------------------------
batch_size 4 <class 'int'>
train_datasets_ids 11,12 <class 'str'>
dev_dataset_id 3 <class 'str'>
test_dataset_id 14 <class 'str'>
reset_stored_filepaths False <class 'bool'>
num_of_gpus 1 <class 'int'>
indexes_of_folders_indicating_class [-2, -3] <class 'list'>
train_val_test_split [0.73982737361, 0.26, 0.13008631319] <class 'list'>
samples_per_iter 1 <class 'int'>
seed 104 <class 'int'>
gpu_to_use 0 <class 'int'>
num_dataprovider_workers 4 <class 'int'>
dataset_name omniglot_dataset <class 'str'>
dataset_path /home/mrvoh/Desktop/datasets/multi_task_class_descr/datasets/omniglot_dataset
dataset_path /home/mrvoh/Desktop/datasets/multi_task_class_descr/datasets/omniglot_dataset <class 'str'>
pretrained_weights bert-base-multilingual-cased <class 'str'>
reset_stored_paths False <class 'bool'>
experiment_name all_experiments-threewayprotomaml/4/ <class 'str'>
continue_from_epoch latest <class 'str'>
num_target_samples 32 <class 'int'>
second_order False <class 'bool'>
first_order_to_second_order_epoch 50 <class 'int'>
total_epochs 100 <class 'int'>
total_iter_per_epoch 100 <class 'int'>
total_epochs_before_pause 50 <class 'int'>
per_step_layer_norm_weights True <class 'bool'>
evalute_on_test_set_only False <class 'bool'>
num_evaluation_tasks 50 <class 'int'>

learnable_per_layer_per_step_inner_loop_learning_rate True <class 'bool'>
enable_inner_loop_optimizable_ln_params None <class 'NoneType'>
init_inner_loop_learning_rate 5e-05 <class 'float'>
min_learning_rate 1e-06 <class 'float'>
meta_learning_rate 3e-05 <class 'float'>
meta_inner_optimizer_learning_rate 6e-05 <class 'float'>
num_classes_per_set 3 <class 'int'>
number_of_training_steps_per_iter 5 <class 'int'>
number_of_evaluation_steps_per_iter 1 <class 'int'>
num_samples_per_class 32 <class 'int'>
eval_using_full_task_set True <class 'bool'>
split_support_and_query True <class 'bool'>
sample_task_to_size_ratio False <class 'bool'>
enable_inner_loop_optimizable_bn_params True <class 'bool'>
shuffle_labels True <class 'bool'>
num_evaluation_seeds 5 <class 'int'>
meta_update_method threewayprotomaml <class 'str'>
init_class_head_lr_multiplier 10 <class 'int'>
gold_label_task_sample_ratio 0 <class 'int'>
num_freeze_epochs 0 <class 'int'>
patience 10 <class 'int'>
train_seed 42 <class 'int'>
val_seed 0 <class 'int'>
evaluate_on_test_set_only False <class 'bool'>
num_start_epochs 0 <class 'int'>
protomaml_do_centralize True <class 'bool'>
val_using_cross_entropy False <class 'bool'>
temperature 1 <class 'int'>
meta_loss ce <class 'str'>
gold_label_tasks [] <class 'list'>
scale_losses False <class 'bool'>
use_swa False <class 'bool'>
num_swa 5 <class 'int'>
use_majority_vote False <class 'bool'>
num_majority_votes 5 <class 'int'>
majority_vote_at_test_only False <class 'bool'>
use_label_guided_learning False <class 'bool'>
use_uncertainty_task_weighting False <class 'bool'>
use_triplet_loss False <class 'bool'>
triplet_loss_in_inner_loop False <class 'bool'>
use_cosine_distance False <class 'bool'>
triplet_loss_margin 0.5 <class 'float'>
triplet_loss_lambda 1.0 <class 'float'>
use_consistency_loss False <class 'bool'>
use_multilingual_consistency_loss False <class 'bool'>
consistency_loss_lambda 1.0 <class 'float'>
consistency_loss_beta 1.0 <class 'float'>
use_convex_feature_space_loss False <class 'bool'>
convex_feature_space_loss_in_inner_loop False <class 'bool'>
convex_feature_space_loss_lambda 1.0 <class 'float'>
convex_feature_space_loss_nr_steps 10 <class 'int'>
use_adapter False <class 'bool'>
proportion_intra_task_sampling 0.85 <class 'float'>
variable_nr_classes_and_samples False <class 'bool'>
finetune_task_name val/RCV2_ja_gt <class 'str'>
num_finetune_epochs 1 <class 'int'>
eval_every_finetune 1 <class 'int'>
finetune_base_model False <class 'bool'>
percentage_train_finetune 0.95 <class 'float'>
factory_finetune False <class 'bool'>
finetune_on_cpu False <class 'bool'>
factory_finetune_tasks_path finetune_tasks.txt <class 'str'>
finetune_out_path finetune_log_old.json <class 'str'>
bootstrap_finetune False <class 'bool'>
num_bootstrap_seeds 5 <class 'int'>
device: %s cuda
Warning! Parameter classifier.dense.weight not loaded from pre-trained checkpoint.
Warning! Parameter classifier.dense.bias not loaded from pre-trained checkpoint.
Warning! Parameter classifier.out_proj.weight not loaded from pre-trained checkpoint.
Warning! Parameter classifier.out_proj.bias not loaded from pre-trained checkpoint.
5e-05
Ranger optimizer loaded. 
Gradient Centralization usage = True
GC applied to both conv and fc layers
Doubling the amount of samples in the support set to split prototype creation and fast adapation...
attempting to find existing checkpoint
data {'train': 6, 'val': 3, 'test': 3}
train_seed 121959, val_seed: 985773, at start time
6100 10000
self.epoch chosen to evaluate on testing set: 61
Loading best model for evaluation..
Evaluating model of epoch: 53
Evaluating ar_test with seed 42...
Evaluating model...
Accuracy 0.5595238095238095
Accuracy: 0.46429
Precision: 0.43619
Recall: 0.32176
F1: 0.36182
Evaluating ar_test with seed 43...
Evaluating model...
Accuracy 0.5714285714285714
Accuracy: 0.45238
Precision: 0.43448
Recall: 0.29861
F1: 0.35281
Evaluating ar_test with seed 44...
Evaluating model...
Accuracy 0.5357142857142857
Accuracy: 0.50000
Precision: 0.43087
Recall: 0.34028
F1: 0.37872
Evaluating ar_test with seed 45...
Evaluating model...
Accuracy 0.6190476190476191
Accuracy: 0.48810
Precision: 0.44201
Recall: 0.33102
F1: 0.37797
Evaluating ar_test with seed 46...
Evaluating model...
Accuracy 0.5595238095238095
Accuracy: 0.45238
Precision: 0.41123
Recall: 0.28704
F1: 0.32679
New best performance for task ar_test
test_accuracy_mean: 0.56905
test_accuracy_std: 0.02756
test_loss_mean: 1.46501
test_loss_std: 0.18656
test_ce_loss_mean: 1.46501
test_ce_loss_std: 0.18656
----------------------------------
batch_size 4 <class 'int'>
train_datasets_ids 11,12 <class 'str'>
dev_dataset_id 3 <class 'str'>
test_dataset_id 14 <class 'str'>
reset_stored_filepaths False <class 'bool'>
num_of_gpus 1 <class 'int'>
indexes_of_folders_indicating_class [-2, -3] <class 'list'>
train_val_test_split [0.73982737361, 0.26, 0.13008631319] <class 'list'>
samples_per_iter 1 <class 'int'>
seed 104 <class 'int'>
gpu_to_use 0 <class 'int'>
num_dataprovider_workers 4 <class 'int'>
dataset_name omniglot_dataset <class 'str'>
dataset_path /home/mrvoh/Desktop/datasets/multi_task_class_descr/datasets/omniglot_dataset
dataset_path /home/mrvoh/Desktop/datasets/multi_task_class_descr/datasets/omniglot_dataset <class 'str'>
pretrained_weights bert-base-multilingual-cased <class 'str'>
reset_stored_paths False <class 'bool'>
experiment_name all_experiments-threewayprotomaml/5/ <class 'str'>
continue_from_epoch latest <class 'str'>
num_target_samples 32 <class 'int'>
second_order False <class 'bool'>
first_order_to_second_order_epoch 50 <class 'int'>
total_epochs 100 <class 'int'>
total_iter_per_epoch 100 <class 'int'>
total_epochs_before_pause 50 <class 'int'>
per_step_layer_norm_weights True <class 'bool'>
evalute_on_test_set_only False <class 'bool'>
num_evaluation_tasks 50 <class 'int'>

learnable_per_layer_per_step_inner_loop_learning_rate True <class 'bool'>
enable_inner_loop_optimizable_ln_params None <class 'NoneType'>
init_inner_loop_learning_rate 5e-05 <class 'float'>
min_learning_rate 1e-06 <class 'float'>
meta_learning_rate 3e-05 <class 'float'>
meta_inner_optimizer_learning_rate 6e-05 <class 'float'>
num_classes_per_set 3 <class 'int'>
number_of_training_steps_per_iter 5 <class 'int'>
number_of_evaluation_steps_per_iter 1 <class 'int'>
num_samples_per_class 32 <class 'int'>
eval_using_full_task_set True <class 'bool'>
split_support_and_query True <class 'bool'>
sample_task_to_size_ratio False <class 'bool'>
enable_inner_loop_optimizable_bn_params True <class 'bool'>
shuffle_labels True <class 'bool'>
num_evaluation_seeds 5 <class 'int'>
meta_update_method threewayprotomaml <class 'str'>
init_class_head_lr_multiplier 10 <class 'int'>
gold_label_task_sample_ratio 0 <class 'int'>
num_freeze_epochs 0 <class 'int'>
patience 10 <class 'int'>
train_seed 42 <class 'int'>
val_seed 0 <class 'int'>
evaluate_on_test_set_only False <class 'bool'>
num_start_epochs 0 <class 'int'>
protomaml_do_centralize True <class 'bool'>
val_using_cross_entropy False <class 'bool'>
temperature 1 <class 'int'>
meta_loss ce <class 'str'>
gold_label_tasks [] <class 'list'>
scale_losses False <class 'bool'>
use_swa False <class 'bool'>
num_swa 5 <class 'int'>
use_majority_vote False <class 'bool'>
num_majority_votes 5 <class 'int'>
majority_vote_at_test_only False <class 'bool'>
use_label_guided_learning False <class 'bool'>
use_uncertainty_task_weighting False <class 'bool'>
use_triplet_loss False <class 'bool'>
triplet_loss_in_inner_loop False <class 'bool'>
use_cosine_distance False <class 'bool'>
triplet_loss_margin 0.5 <class 'float'>
triplet_loss_lambda 1.0 <class 'float'>
use_consistency_loss False <class 'bool'>
use_multilingual_consistency_loss False <class 'bool'>
consistency_loss_lambda 1.0 <class 'float'>
consistency_loss_beta 1.0 <class 'float'>
use_convex_feature_space_loss False <class 'bool'>
convex_feature_space_loss_in_inner_loop False <class 'bool'>
convex_feature_space_loss_lambda 1.0 <class 'float'>
convex_feature_space_loss_nr_steps 10 <class 'int'>
use_adapter False <class 'bool'>
proportion_intra_task_sampling 0.85 <class 'float'>
variable_nr_classes_and_samples False <class 'bool'>
finetune_task_name val/RCV2_ja_gt <class 'str'>
num_finetune_epochs 1 <class 'int'>
eval_every_finetune 1 <class 'int'>
finetune_base_model False <class 'bool'>
percentage_train_finetune 0.95 <class 'float'>
factory_finetune False <class 'bool'>
finetune_on_cpu False <class 'bool'>
factory_finetune_tasks_path finetune_tasks.txt <class 'str'>
finetune_out_path finetune_log_old.json <class 'str'>
bootstrap_finetune False <class 'bool'>
num_bootstrap_seeds 5 <class 'int'>
device: %s cuda
Warning! Parameter classifier.dense.weight not loaded from pre-trained checkpoint.
Warning! Parameter classifier.dense.bias not loaded from pre-trained checkpoint.
Warning! Parameter classifier.out_proj.weight not loaded from pre-trained checkpoint.
Warning! Parameter classifier.out_proj.bias not loaded from pre-trained checkpoint.
5e-05
Ranger optimizer loaded. 
Gradient Centralization usage = True
GC applied to both conv and fc layers
Doubling the amount of samples in the support set to split prototype creation and fast adapation...
attempting to find existing checkpoint
data {'train': 6, 'val': 3, 'test': 3}
train_seed 121959, val_seed: 985773, at start time
6100 10000
self.epoch chosen to evaluate on testing set: 61
Loading best model for evaluation..
Evaluating model of epoch: 54
Evaluating ar_test with seed 42...
Evaluating model...
Accuracy 0.5476190476190477
Accuracy: 0.47619
Precision: 0.44029
Recall: 0.32870
F1: 0.36873
Evaluating ar_test with seed 43...
Evaluating model...
Accuracy 0.6428571428571429
Accuracy: 0.52381
Precision: 0.50498
Recall: 0.36111
F1: 0.41658
Evaluating ar_test with seed 44...
Evaluating model...
Accuracy 0.5119047619047619
Accuracy: 0.34524
Precision: 0.35260
Recall: 0.23148
F1: 0.27947
Evaluating ar_test with seed 45...
Evaluating model...
Accuracy 0.6071428571428571
Accuracy: 0.47619
Precision: 0.46160
Recall: 0.33102
F1: 0.37646
Evaluating ar_test with seed 46...
Evaluating model...
Accuracy 0.6428571428571429
Accuracy: 0.52381
Precision: 0.48413
Recall: 0.36806
F1: 0.39502
New best performance for task ar_test
test_accuracy_mean: 0.59048
test_accuracy_std: 0.05249
test_loss_mean: 1.39660
test_loss_std: 0.34496
test_ce_loss_mean: 1.39660
test_ce_loss_std: 0.34496
----------------------------------
batch_size 4 <class 'int'>
train_datasets_ids 11,12 <class 'str'>
dev_dataset_id 3 <class 'str'>
test_dataset_id 14 <class 'str'>
reset_stored_filepaths False <class 'bool'>
num_of_gpus 1 <class 'int'>
indexes_of_folders_indicating_class [-2, -3] <class 'list'>
train_val_test_split [0.73982737361, 0.26, 0.13008631319] <class 'list'>
samples_per_iter 1 <class 'int'>
seed 104 <class 'int'>
gpu_to_use 0 <class 'int'>
num_dataprovider_workers 4 <class 'int'>
dataset_name omniglot_dataset <class 'str'>
dataset_path /home/mrvoh/Desktop/datasets/multi_task_class_descr/datasets/omniglot_dataset
dataset_path /home/mrvoh/Desktop/datasets/multi_task_class_descr/datasets/omniglot_dataset <class 'str'>
pretrained_weights bert-base-multilingual-cased <class 'str'>
reset_stored_paths False <class 'bool'>
experiment_name all_experiments-threewayprotomaml/6/ <class 'str'>
continue_from_epoch latest <class 'str'>
num_target_samples 32 <class 'int'>
second_order False <class 'bool'>
first_order_to_second_order_epoch 50 <class 'int'>
total_epochs 100 <class 'int'>
total_iter_per_epoch 100 <class 'int'>
total_epochs_before_pause 50 <class 'int'>
per_step_layer_norm_weights True <class 'bool'>
evalute_on_test_set_only False <class 'bool'>
num_evaluation_tasks 50 <class 'int'>

learnable_per_layer_per_step_inner_loop_learning_rate True <class 'bool'>
enable_inner_loop_optimizable_ln_params None <class 'NoneType'>
init_inner_loop_learning_rate 5e-05 <class 'float'>
min_learning_rate 1e-06 <class 'float'>
meta_learning_rate 3e-05 <class 'float'>
meta_inner_optimizer_learning_rate 6e-05 <class 'float'>
num_classes_per_set 3 <class 'int'>
number_of_training_steps_per_iter 5 <class 'int'>
number_of_evaluation_steps_per_iter 1 <class 'int'>
num_samples_per_class 32 <class 'int'>
eval_using_full_task_set True <class 'bool'>
split_support_and_query True <class 'bool'>
sample_task_to_size_ratio False <class 'bool'>
enable_inner_loop_optimizable_bn_params True <class 'bool'>
shuffle_labels True <class 'bool'>
num_evaluation_seeds 5 <class 'int'>
meta_update_method threewayprotomaml <class 'str'>
init_class_head_lr_multiplier 10 <class 'int'>
gold_label_task_sample_ratio 0 <class 'int'>
num_freeze_epochs 0 <class 'int'>
patience 10 <class 'int'>
train_seed 42 <class 'int'>
val_seed 0 <class 'int'>
evaluate_on_test_set_only False <class 'bool'>
num_start_epochs 0 <class 'int'>
protomaml_do_centralize True <class 'bool'>
val_using_cross_entropy False <class 'bool'>
temperature 1 <class 'int'>
meta_loss ce <class 'str'>
gold_label_tasks [] <class 'list'>
scale_losses False <class 'bool'>
use_swa False <class 'bool'>
num_swa 5 <class 'int'>
use_majority_vote False <class 'bool'>
num_majority_votes 5 <class 'int'>
majority_vote_at_test_only False <class 'bool'>
use_label_guided_learning False <class 'bool'>
use_uncertainty_task_weighting False <class 'bool'>
use_triplet_loss False <class 'bool'>
triplet_loss_in_inner_loop False <class 'bool'>
use_cosine_distance False <class 'bool'>
triplet_loss_margin 0.5 <class 'float'>
triplet_loss_lambda 1.0 <class 'float'>
use_consistency_loss False <class 'bool'>
use_multilingual_consistency_loss False <class 'bool'>
consistency_loss_lambda 1.0 <class 'float'>
consistency_loss_beta 1.0 <class 'float'>
use_convex_feature_space_loss False <class 'bool'>
convex_feature_space_loss_in_inner_loop False <class 'bool'>
convex_feature_space_loss_lambda 1.0 <class 'float'>
convex_feature_space_loss_nr_steps 10 <class 'int'>
use_adapter False <class 'bool'>
proportion_intra_task_sampling 0.85 <class 'float'>
variable_nr_classes_and_samples False <class 'bool'>
finetune_task_name val/RCV2_ja_gt <class 'str'>
num_finetune_epochs 1 <class 'int'>
eval_every_finetune 1 <class 'int'>
finetune_base_model False <class 'bool'>
percentage_train_finetune 0.95 <class 'float'>
factory_finetune False <class 'bool'>
finetune_on_cpu False <class 'bool'>
factory_finetune_tasks_path finetune_tasks.txt <class 'str'>
finetune_out_path finetune_log_old.json <class 'str'>
bootstrap_finetune False <class 'bool'>
num_bootstrap_seeds 5 <class 'int'>
device: %s cuda
Warning! Parameter classifier.dense.weight not loaded from pre-trained checkpoint.
Warning! Parameter classifier.dense.bias not loaded from pre-trained checkpoint.
Warning! Parameter classifier.out_proj.weight not loaded from pre-trained checkpoint.
Warning! Parameter classifier.out_proj.bias not loaded from pre-trained checkpoint.
5e-05
Ranger optimizer loaded. 
Gradient Centralization usage = True
GC applied to both conv and fc layers
Doubling the amount of samples in the support set to split prototype creation and fast adapation...
attempting to find existing checkpoint
data {'train': 6, 'val': 3, 'test': 3}
train_seed 121959, val_seed: 985773, at start time
6000 10000
self.epoch chosen to evaluate on testing set: 60
Loading best model for evaluation..
Evaluating model of epoch: 54
Evaluating ar_test with seed 42...
Evaluating model...
Accuracy 0.5595238095238095
Accuracy: 0.47619
Precision: 0.43787
Recall: 0.33102
F1: 0.36461
Evaluating ar_test with seed 43...
Evaluating model...
Accuracy 0.6071428571428571
Accuracy: 0.51190
Precision: 0.42781
Recall: 0.34722
F1: 0.38176
Evaluating ar_test with seed 44...
Evaluating model...
Accuracy 0.5357142857142857
Accuracy: 0.50000
Precision: 0.42992
Recall: 0.33102
F1: 0.37306
Evaluating ar_test with seed 45...
Evaluating model...
Accuracy 0.5595238095238095
Accuracy: 0.42857
Precision: 0.42581
Recall: 0.29861
F1: 0.34594
Evaluating ar_test with seed 46...
Evaluating model...
Accuracy 0.5357142857142857
Accuracy: 0.45238
Precision: 0.42857
Recall: 0.28704
F1: 0.32577
New best performance for task ar_test
test_accuracy_mean: 0.55952
test_accuracy_std: 0.02608
test_loss_mean: 1.46399
test_loss_std: 0.09937
test_ce_loss_mean: 1.46399
test_ce_loss_std: 0.09937
----------------------------------
batch_size 4 <class 'int'>
train_datasets_ids 11,12 <class 'str'>
dev_dataset_id 3 <class 'str'>
test_dataset_id 14 <class 'str'>
reset_stored_filepaths False <class 'bool'>
num_of_gpus 1 <class 'int'>
indexes_of_folders_indicating_class [-2, -3] <class 'list'>
train_val_test_split [0.73982737361, 0.26, 0.13008631319] <class 'list'>
samples_per_iter 1 <class 'int'>
seed 104 <class 'int'>
gpu_to_use 0 <class 'int'>
num_dataprovider_workers 4 <class 'int'>
dataset_name omniglot_dataset <class 'str'>
dataset_path /home/mrvoh/Desktop/datasets/multi_task_class_descr/datasets/omniglot_dataset
dataset_path /home/mrvoh/Desktop/datasets/multi_task_class_descr/datasets/omniglot_dataset <class 'str'>
pretrained_weights bert-base-multilingual-cased <class 'str'>
reset_stored_paths False <class 'bool'>
experiment_name all_experiments-threewayprotomaml/7/ <class 'str'>
continue_from_epoch latest <class 'str'>
num_target_samples 32 <class 'int'>
second_order False <class 'bool'>
first_order_to_second_order_epoch 50 <class 'int'>
total_epochs 100 <class 'int'>
total_iter_per_epoch 100 <class 'int'>
total_epochs_before_pause 50 <class 'int'>
per_step_layer_norm_weights True <class 'bool'>
evalute_on_test_set_only False <class 'bool'>
num_evaluation_tasks 50 <class 'int'>

learnable_per_layer_per_step_inner_loop_learning_rate True <class 'bool'>
enable_inner_loop_optimizable_ln_params None <class 'NoneType'>
init_inner_loop_learning_rate 5e-05 <class 'float'>
min_learning_rate 1e-06 <class 'float'>
meta_learning_rate 3e-05 <class 'float'>
meta_inner_optimizer_learning_rate 6e-05 <class 'float'>
num_classes_per_set 3 <class 'int'>
number_of_training_steps_per_iter 5 <class 'int'>
number_of_evaluation_steps_per_iter 1 <class 'int'>
num_samples_per_class 32 <class 'int'>
eval_using_full_task_set True <class 'bool'>
split_support_and_query True <class 'bool'>
sample_task_to_size_ratio False <class 'bool'>
enable_inner_loop_optimizable_bn_params True <class 'bool'>
shuffle_labels True <class 'bool'>
num_evaluation_seeds 5 <class 'int'>
meta_update_method threewayprotomaml <class 'str'>
init_class_head_lr_multiplier 10 <class 'int'>
gold_label_task_sample_ratio 0 <class 'int'>
num_freeze_epochs 0 <class 'int'>
patience 10 <class 'int'>
train_seed 42 <class 'int'>
val_seed 0 <class 'int'>
evaluate_on_test_set_only False <class 'bool'>
num_start_epochs 0 <class 'int'>
protomaml_do_centralize True <class 'bool'>
val_using_cross_entropy False <class 'bool'>
temperature 1 <class 'int'>
meta_loss ce <class 'str'>
gold_label_tasks [] <class 'list'>
scale_losses False <class 'bool'>
use_swa False <class 'bool'>
num_swa 5 <class 'int'>
use_majority_vote False <class 'bool'>
num_majority_votes 5 <class 'int'>
majority_vote_at_test_only False <class 'bool'>
use_label_guided_learning False <class 'bool'>
use_uncertainty_task_weighting False <class 'bool'>
use_triplet_loss False <class 'bool'>
triplet_loss_in_inner_loop False <class 'bool'>
use_cosine_distance False <class 'bool'>
triplet_loss_margin 0.5 <class 'float'>
triplet_loss_lambda 1.0 <class 'float'>
use_consistency_loss False <class 'bool'>
use_multilingual_consistency_loss False <class 'bool'>
consistency_loss_lambda 1.0 <class 'float'>
consistency_loss_beta 1.0 <class 'float'>
use_convex_feature_space_loss False <class 'bool'>
convex_feature_space_loss_in_inner_loop False <class 'bool'>
convex_feature_space_loss_lambda 1.0 <class 'float'>
convex_feature_space_loss_nr_steps 10 <class 'int'>
use_adapter False <class 'bool'>
proportion_intra_task_sampling 0.85 <class 'float'>
variable_nr_classes_and_samples False <class 'bool'>
finetune_task_name val/RCV2_ja_gt <class 'str'>
num_finetune_epochs 1 <class 'int'>
eval_every_finetune 1 <class 'int'>
finetune_base_model False <class 'bool'>
percentage_train_finetune 0.95 <class 'float'>
factory_finetune False <class 'bool'>
finetune_on_cpu False <class 'bool'>
factory_finetune_tasks_path finetune_tasks.txt <class 'str'>
finetune_out_path finetune_log_old.json <class 'str'>
bootstrap_finetune False <class 'bool'>
num_bootstrap_seeds 5 <class 'int'>
device: %s cuda
Warning! Parameter classifier.dense.weight not loaded from pre-trained checkpoint.
Warning! Parameter classifier.dense.bias not loaded from pre-trained checkpoint.
Warning! Parameter classifier.out_proj.weight not loaded from pre-trained checkpoint.
Warning! Parameter classifier.out_proj.bias not loaded from pre-trained checkpoint.
5e-05
Ranger optimizer loaded. 
Gradient Centralization usage = True
GC applied to both conv and fc layers
Doubling the amount of samples in the support set to split prototype creation and fast adapation...
attempting to find existing checkpoint
data {'train': 6, 'val': 3, 'test': 3}
train_seed 121959, val_seed: 985773, at start time
5700 10000
self.epoch chosen to evaluate on testing set: 57
Loading best model for evaluation..
Evaluating model of epoch: 49
Evaluating ar_test with seed 42...
Evaluating model...
Accuracy 0.5119047619047619
Accuracy: 0.42857
Precision: 0.35799
Recall: 0.29398
F1: 0.32087
Evaluating ar_test with seed 43...
Evaluating model...
Accuracy 0.5595238095238095
Accuracy: 0.50000
Precision: 0.42885
Recall: 0.35185
F1: 0.36690
Evaluating ar_test with seed 44...
Evaluating model...
Accuracy 0.5357142857142857
Accuracy: 0.45238
Precision: 0.39622
Recall: 0.30787
F1: 0.34543
Evaluating ar_test with seed 45...
Evaluating model...
Accuracy 0.6428571428571429
Accuracy: 0.54762
Precision: 0.46507
Recall: 0.37269
F1: 0.41248
Evaluating ar_test with seed 46...
Evaluating model...
Accuracy 0.5833333333333334
Accuracy: 0.50000
Precision: 0.43810
Recall: 0.32639
F1: 0.36899
New best performance for task ar_test
test_accuracy_mean: 0.56667
test_accuracy_std: 0.04492
test_loss_mean: 1.42181
test_loss_std: 0.31691
test_ce_loss_mean: 1.42181
test_ce_loss_std: 0.31691
----------------------------------
batch_size 4 <class 'int'>
train_datasets_ids 11,12 <class 'str'>
dev_dataset_id 3 <class 'str'>
test_dataset_id 14 <class 'str'>
reset_stored_filepaths False <class 'bool'>
num_of_gpus 1 <class 'int'>
indexes_of_folders_indicating_class [-2, -3] <class 'list'>
train_val_test_split [0.73982737361, 0.26, 0.13008631319] <class 'list'>
samples_per_iter 1 <class 'int'>
seed 104 <class 'int'>
gpu_to_use 0 <class 'int'>
num_dataprovider_workers 4 <class 'int'>
dataset_name omniglot_dataset <class 'str'>
dataset_path /home/mrvoh/Desktop/datasets/multi_task_class_descr/datasets/omniglot_dataset
dataset_path /home/mrvoh/Desktop/datasets/multi_task_class_descr/datasets/omniglot_dataset <class 'str'>
pretrained_weights bert-base-multilingual-cased <class 'str'>
reset_stored_paths False <class 'bool'>
experiment_name all_experiments-threewayprotomaml/8/ <class 'str'>
continue_from_epoch latest <class 'str'>
num_target_samples 32 <class 'int'>
second_order False <class 'bool'>
first_order_to_second_order_epoch 50 <class 'int'>
total_epochs 100 <class 'int'>
total_iter_per_epoch 100 <class 'int'>
total_epochs_before_pause 50 <class 'int'>
per_step_layer_norm_weights True <class 'bool'>
evalute_on_test_set_only False <class 'bool'>
num_evaluation_tasks 50 <class 'int'>

learnable_per_layer_per_step_inner_loop_learning_rate True <class 'bool'>
enable_inner_loop_optimizable_ln_params None <class 'NoneType'>
init_inner_loop_learning_rate 5e-05 <class 'float'>
min_learning_rate 1e-06 <class 'float'>
meta_learning_rate 3e-05 <class 'float'>
meta_inner_optimizer_learning_rate 6e-05 <class 'float'>
num_classes_per_set 3 <class 'int'>
number_of_training_steps_per_iter 5 <class 'int'>
number_of_evaluation_steps_per_iter 1 <class 'int'>
num_samples_per_class 32 <class 'int'>
eval_using_full_task_set True <class 'bool'>
split_support_and_query True <class 'bool'>
sample_task_to_size_ratio False <class 'bool'>
enable_inner_loop_optimizable_bn_params True <class 'bool'>
shuffle_labels True <class 'bool'>
num_evaluation_seeds 5 <class 'int'>
meta_update_method threewayprotomaml <class 'str'>
init_class_head_lr_multiplier 10 <class 'int'>
gold_label_task_sample_ratio 0 <class 'int'>
num_freeze_epochs 0 <class 'int'>
patience 10 <class 'int'>
train_seed 42 <class 'int'>
val_seed 0 <class 'int'>
evaluate_on_test_set_only False <class 'bool'>
num_start_epochs 0 <class 'int'>
protomaml_do_centralize True <class 'bool'>
val_using_cross_entropy False <class 'bool'>
temperature 1 <class 'int'>
meta_loss ce <class 'str'>
gold_label_tasks [] <class 'list'>
scale_losses False <class 'bool'>
use_swa False <class 'bool'>
num_swa 5 <class 'int'>
use_majority_vote False <class 'bool'>
num_majority_votes 5 <class 'int'>
majority_vote_at_test_only False <class 'bool'>
use_label_guided_learning False <class 'bool'>
use_uncertainty_task_weighting False <class 'bool'>
use_triplet_loss False <class 'bool'>
triplet_loss_in_inner_loop False <class 'bool'>
use_cosine_distance False <class 'bool'>
triplet_loss_margin 0.5 <class 'float'>
triplet_loss_lambda 1.0 <class 'float'>
use_consistency_loss False <class 'bool'>
use_multilingual_consistency_loss False <class 'bool'>
consistency_loss_lambda 1.0 <class 'float'>
consistency_loss_beta 1.0 <class 'float'>
use_convex_feature_space_loss False <class 'bool'>
convex_feature_space_loss_in_inner_loop False <class 'bool'>
convex_feature_space_loss_lambda 1.0 <class 'float'>
convex_feature_space_loss_nr_steps 10 <class 'int'>
use_adapter False <class 'bool'>
proportion_intra_task_sampling 0.85 <class 'float'>
variable_nr_classes_and_samples False <class 'bool'>
finetune_task_name val/RCV2_ja_gt <class 'str'>
num_finetune_epochs 1 <class 'int'>
eval_every_finetune 1 <class 'int'>
finetune_base_model False <class 'bool'>
percentage_train_finetune 0.95 <class 'float'>
factory_finetune False <class 'bool'>
finetune_on_cpu False <class 'bool'>
factory_finetune_tasks_path finetune_tasks.txt <class 'str'>
finetune_out_path finetune_log_old.json <class 'str'>
bootstrap_finetune False <class 'bool'>
num_bootstrap_seeds 5 <class 'int'>
device: %s cuda
Warning! Parameter classifier.dense.weight not loaded from pre-trained checkpoint.
Warning! Parameter classifier.dense.bias not loaded from pre-trained checkpoint.
Warning! Parameter classifier.out_proj.weight not loaded from pre-trained checkpoint.
Warning! Parameter classifier.out_proj.bias not loaded from pre-trained checkpoint.
5e-05
Ranger optimizer loaded. 
Gradient Centralization usage = True
GC applied to both conv and fc layers
Doubling the amount of samples in the support set to split prototype creation and fast adapation...
attempting to find existing checkpoint
data {'train': 6, 'val': 3, 'test': 3}
train_seed 121959, val_seed: 985773, at start time
6000 10000
self.epoch chosen to evaluate on testing set: 60
Loading best model for evaluation..
Evaluating model of epoch: 49
Evaluating ar_test with seed 42...
Evaluating model...
Accuracy 0.6190476190476191
Accuracy: 0.51190
Precision: 0.47523
Recall: 0.35648
F1: 0.39498
Evaluating ar_test with seed 43...
Evaluating model...
Accuracy 0.5952380952380952
Accuracy: 0.42857
Precision: 0.46477
Recall: 0.28935
F1: 0.35659
Evaluating ar_test with seed 44...
Evaluating model...
Accuracy 0.6071428571428571
Accuracy: 0.58333
Precision: 0.48070
Recall: 0.38889
F1: 0.42994
Evaluating ar_test with seed 45...
Evaluating model...
Accuracy 0.5119047619047619
Accuracy: 0.38095
Precision: 0.39652
Recall: 0.26157
F1: 0.31437
Evaluating ar_test with seed 46...
Evaluating model...
Accuracy 0.5952380952380952
Accuracy: 0.46429
Precision: 0.43889
Recall: 0.29630
F1: 0.33824
New best performance for task ar_test
test_accuracy_mean: 0.58571
test_accuracy_std: 0.03795
test_loss_mean: 1.42818
test_loss_std: 0.06238
test_ce_loss_mean: 1.42818
test_ce_loss_std: 0.06238
----------------------------------
batch_size 4 <class 'int'>
train_datasets_ids 11,12 <class 'str'>
dev_dataset_id 3 <class 'str'>
test_dataset_id 14 <class 'str'>
reset_stored_filepaths False <class 'bool'>
num_of_gpus 1 <class 'int'>
indexes_of_folders_indicating_class [-2, -3] <class 'list'>
train_val_test_split [0.73982737361, 0.26, 0.13008631319] <class 'list'>
samples_per_iter 1 <class 'int'>
seed 104 <class 'int'>
gpu_to_use 0 <class 'int'>
num_dataprovider_workers 4 <class 'int'>
dataset_name omniglot_dataset <class 'str'>
dataset_path /home/mrvoh/Desktop/datasets/multi_task_class_descr/datasets/omniglot_dataset
dataset_path /home/mrvoh/Desktop/datasets/multi_task_class_descr/datasets/omniglot_dataset <class 'str'>
pretrained_weights bert-base-multilingual-cased <class 'str'>
reset_stored_paths False <class 'bool'>
experiment_name all_experiments-threewayprotomaml/9/ <class 'str'>
continue_from_epoch latest <class 'str'>
num_target_samples 32 <class 'int'>
second_order False <class 'bool'>
first_order_to_second_order_epoch 50 <class 'int'>
total_epochs 100 <class 'int'>
total_iter_per_epoch 100 <class 'int'>
total_epochs_before_pause 50 <class 'int'>
per_step_layer_norm_weights True <class 'bool'>
evalute_on_test_set_only False <class 'bool'>
num_evaluation_tasks 50 <class 'int'>

learnable_per_layer_per_step_inner_loop_learning_rate True <class 'bool'>
enable_inner_loop_optimizable_ln_params None <class 'NoneType'>
init_inner_loop_learning_rate 5e-05 <class 'float'>
min_learning_rate 1e-06 <class 'float'>
meta_learning_rate 3e-05 <class 'float'>
meta_inner_optimizer_learning_rate 6e-05 <class 'float'>
num_classes_per_set 3 <class 'int'>
number_of_training_steps_per_iter 5 <class 'int'>
number_of_evaluation_steps_per_iter 1 <class 'int'>
num_samples_per_class 32 <class 'int'>
eval_using_full_task_set True <class 'bool'>
split_support_and_query True <class 'bool'>
sample_task_to_size_ratio False <class 'bool'>
enable_inner_loop_optimizable_bn_params True <class 'bool'>
shuffle_labels True <class 'bool'>
num_evaluation_seeds 5 <class 'int'>
meta_update_method threewayprotomaml <class 'str'>
init_class_head_lr_multiplier 10 <class 'int'>
gold_label_task_sample_ratio 0 <class 'int'>
num_freeze_epochs 0 <class 'int'>
patience 10 <class 'int'>
train_seed 42 <class 'int'>
val_seed 0 <class 'int'>
evaluate_on_test_set_only False <class 'bool'>
num_start_epochs 0 <class 'int'>
protomaml_do_centralize True <class 'bool'>
val_using_cross_entropy False <class 'bool'>
temperature 1 <class 'int'>
meta_loss ce <class 'str'>
gold_label_tasks [] <class 'list'>
scale_losses False <class 'bool'>
use_swa False <class 'bool'>
num_swa 5 <class 'int'>
use_majority_vote False <class 'bool'>
num_majority_votes 5 <class 'int'>
majority_vote_at_test_only False <class 'bool'>
use_label_guided_learning False <class 'bool'>
use_uncertainty_task_weighting False <class 'bool'>
use_triplet_loss False <class 'bool'>
triplet_loss_in_inner_loop False <class 'bool'>
use_cosine_distance False <class 'bool'>
triplet_loss_margin 0.5 <class 'float'>
triplet_loss_lambda 1.0 <class 'float'>
use_consistency_loss False <class 'bool'>
use_multilingual_consistency_loss False <class 'bool'>
consistency_loss_lambda 1.0 <class 'float'>
consistency_loss_beta 1.0 <class 'float'>
use_convex_feature_space_loss False <class 'bool'>
convex_feature_space_loss_in_inner_loop False <class 'bool'>
convex_feature_space_loss_lambda 1.0 <class 'float'>
convex_feature_space_loss_nr_steps 10 <class 'int'>
use_adapter False <class 'bool'>
proportion_intra_task_sampling 0.85 <class 'float'>
variable_nr_classes_and_samples False <class 'bool'>
finetune_task_name val/RCV2_ja_gt <class 'str'>
num_finetune_epochs 1 <class 'int'>
eval_every_finetune 1 <class 'int'>
finetune_base_model False <class 'bool'>
percentage_train_finetune 0.95 <class 'float'>
factory_finetune False <class 'bool'>
finetune_on_cpu False <class 'bool'>
factory_finetune_tasks_path finetune_tasks.txt <class 'str'>
finetune_out_path finetune_log_old.json <class 'str'>
bootstrap_finetune False <class 'bool'>
num_bootstrap_seeds 5 <class 'int'>
device: %s cuda
Warning! Parameter classifier.dense.weight not loaded from pre-trained checkpoint.
Warning! Parameter classifier.dense.bias not loaded from pre-trained checkpoint.
Warning! Parameter classifier.out_proj.weight not loaded from pre-trained checkpoint.
Warning! Parameter classifier.out_proj.bias not loaded from pre-trained checkpoint.
5e-05
Ranger optimizer loaded. 
Gradient Centralization usage = True
GC applied to both conv and fc layers
Doubling the amount of samples in the support set to split prototype creation and fast adapation...
attempting to find existing checkpoint
data {'train': 6, 'val': 3, 'test': 3}
train_seed 121959, val_seed: 985773, at start time
5800 10000
self.epoch chosen to evaluate on testing set: 58
Loading best model for evaluation..
Evaluating model of epoch: 49
Evaluating ar_test with seed 42...
Evaluating model...
Accuracy 0.5595238095238095
Accuracy: 0.47619
Precision: 0.45299
Recall: 0.32870
F1: 0.37472
Evaluating ar_test with seed 43...
Evaluating model...
Accuracy 0.6666666666666666
Accuracy: 0.54762
Precision: 0.51042
Recall: 0.37731
F1: 0.42931
Evaluating ar_test with seed 44...
Evaluating model...
Accuracy 0.5119047619047619
Accuracy: 0.38095
Precision: 0.36137
Recall: 0.25694
F1: 0.29971
Evaluating ar_test with seed 45...
Evaluating model...
Accuracy 0.6071428571428571
Accuracy: 0.48810
Precision: 0.43571
Recall: 0.33565
F1: 0.37324
Evaluating ar_test with seed 46...
Evaluating model...
Accuracy 0.6547619047619048
Accuracy: 0.52381
Precision: 0.45568
Recall: 0.36806
F1: 0.38747
New best performance for task ar_test
test_accuracy_mean: 0.60000
test_accuracy_std: 0.05813
test_loss_mean: 1.30796
test_loss_std: 0.28100
test_ce_loss_mean: 1.30796
test_ce_loss_std: 0.28100
----------------------------------
batch_size 4 <class 'int'>
train_datasets_ids 11,12 <class 'str'>
dev_dataset_id 3 <class 'str'>
test_dataset_id 14 <class 'str'>
reset_stored_filepaths False <class 'bool'>
num_of_gpus 1 <class 'int'>
indexes_of_folders_indicating_class [-2, -3] <class 'list'>
train_val_test_split [0.73982737361, 0.26, 0.13008631319] <class 'list'>
samples_per_iter 1 <class 'int'>
seed 104 <class 'int'>
gpu_to_use 0 <class 'int'>
num_dataprovider_workers 4 <class 'int'>
dataset_name omniglot_dataset <class 'str'>
dataset_path /home/mrvoh/Desktop/datasets/multi_task_class_descr/datasets/omniglot_dataset
dataset_path /home/mrvoh/Desktop/datasets/multi_task_class_descr/datasets/omniglot_dataset <class 'str'>
pretrained_weights bert-base-multilingual-cased <class 'str'>
reset_stored_paths False <class 'bool'>
experiment_name all_experiments-threewayprotomaml/10/ <class 'str'>
continue_from_epoch latest <class 'str'>
num_target_samples 32 <class 'int'>
second_order False <class 'bool'>
first_order_to_second_order_epoch 50 <class 'int'>
total_epochs 100 <class 'int'>
total_iter_per_epoch 100 <class 'int'>
total_epochs_before_pause 50 <class 'int'>
per_step_layer_norm_weights True <class 'bool'>
evalute_on_test_set_only False <class 'bool'>
num_evaluation_tasks 50 <class 'int'>

learnable_per_layer_per_step_inner_loop_learning_rate True <class 'bool'>
enable_inner_loop_optimizable_ln_params None <class 'NoneType'>
init_inner_loop_learning_rate 5e-05 <class 'float'>
min_learning_rate 1e-06 <class 'float'>
meta_learning_rate 3e-05 <class 'float'>
meta_inner_optimizer_learning_rate 6e-05 <class 'float'>
num_classes_per_set 3 <class 'int'>
number_of_training_steps_per_iter 5 <class 'int'>
number_of_evaluation_steps_per_iter 1 <class 'int'>
num_samples_per_class 32 <class 'int'>
eval_using_full_task_set True <class 'bool'>
split_support_and_query True <class 'bool'>
sample_task_to_size_ratio False <class 'bool'>
enable_inner_loop_optimizable_bn_params True <class 'bool'>
shuffle_labels True <class 'bool'>
num_evaluation_seeds 5 <class 'int'>
meta_update_method threewayprotomaml <class 'str'>
init_class_head_lr_multiplier 10 <class 'int'>
gold_label_task_sample_ratio 0 <class 'int'>
num_freeze_epochs 0 <class 'int'>
patience 10 <class 'int'>
train_seed 42 <class 'int'>
val_seed 0 <class 'int'>
evaluate_on_test_set_only False <class 'bool'>
num_start_epochs 0 <class 'int'>
protomaml_do_centralize True <class 'bool'>
val_using_cross_entropy False <class 'bool'>
temperature 1 <class 'int'>
meta_loss ce <class 'str'>
gold_label_tasks [] <class 'list'>
scale_losses False <class 'bool'>
use_swa False <class 'bool'>
num_swa 5 <class 'int'>
use_majority_vote False <class 'bool'>
num_majority_votes 5 <class 'int'>
majority_vote_at_test_only False <class 'bool'>
use_label_guided_learning False <class 'bool'>
use_uncertainty_task_weighting False <class 'bool'>
use_triplet_loss False <class 'bool'>
triplet_loss_in_inner_loop False <class 'bool'>
use_cosine_distance False <class 'bool'>
triplet_loss_margin 0.5 <class 'float'>
triplet_loss_lambda 1.0 <class 'float'>
use_consistency_loss False <class 'bool'>
use_multilingual_consistency_loss False <class 'bool'>
consistency_loss_lambda 1.0 <class 'float'>
consistency_loss_beta 1.0 <class 'float'>
use_convex_feature_space_loss False <class 'bool'>
convex_feature_space_loss_in_inner_loop False <class 'bool'>
convex_feature_space_loss_lambda 1.0 <class 'float'>
convex_feature_space_loss_nr_steps 10 <class 'int'>
use_adapter False <class 'bool'>
proportion_intra_task_sampling 0.85 <class 'float'>
variable_nr_classes_and_samples False <class 'bool'>
finetune_task_name val/RCV2_ja_gt <class 'str'>
num_finetune_epochs 1 <class 'int'>
eval_every_finetune 1 <class 'int'>
finetune_base_model False <class 'bool'>
percentage_train_finetune 0.95 <class 'float'>
factory_finetune False <class 'bool'>
finetune_on_cpu False <class 'bool'>
factory_finetune_tasks_path finetune_tasks.txt <class 'str'>
finetune_out_path finetune_log_old.json <class 'str'>
bootstrap_finetune False <class 'bool'>
num_bootstrap_seeds 5 <class 'int'>
device: %s cuda
Warning! Parameter classifier.dense.weight not loaded from pre-trained checkpoint.
Warning! Parameter classifier.dense.bias not loaded from pre-trained checkpoint.
Warning! Parameter classifier.out_proj.weight not loaded from pre-trained checkpoint.
Warning! Parameter classifier.out_proj.bias not loaded from pre-trained checkpoint.
5e-05
Ranger optimizer loaded. 
Gradient Centralization usage = True
GC applied to both conv and fc layers
Doubling the amount of samples in the support set to split prototype creation and fast adapation...
attempting to find existing checkpoint
data {'train': 6, 'val': 3, 'test': 3}
train_seed 121959, val_seed: 985773, at start time
4800 10000
self.epoch chosen to evaluate on testing set: 48
Loading best model for evaluation..
Evaluating model of epoch: 46
Evaluating ar_test with seed 42...
Evaluating model...
Accuracy 0.5119047619047619
Accuracy: 0.48810
Precision: 0.39855
Recall: 0.31713
F1: 0.34968
Evaluating ar_test with seed 43...
Evaluating model...
Accuracy 0.5714285714285714
Accuracy: 0.40476
Precision: 0.47808
Recall: 0.26620
F1: 0.33464
Evaluating ar_test with seed 44...
Evaluating model...
Accuracy 0.5952380952380952
Accuracy: 0.54762
Precision: 0.42580
Recall: 0.36806
F1: 0.39447
Evaluating ar_test with seed 45...
Evaluating model...
Accuracy 0.5357142857142857
Accuracy: 0.46429
Precision: 0.38996
Recall: 0.30093
F1: 0.33737
Evaluating ar_test with seed 46...
Evaluating model...
Accuracy 0.5595238095238095
Accuracy: 0.44048
Precision: 0.38256
Recall: 0.29630
F1: 0.33395
New best performance for task ar_test
test_accuracy_mean: 0.55476
test_accuracy_std: 0.02877
test_loss_mean: 1.29092
test_loss_std: 0.16747
test_ce_loss_mean: 1.29092
test_ce_loss_std: 0.16747
