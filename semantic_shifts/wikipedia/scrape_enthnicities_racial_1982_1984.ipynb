{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec773491",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import wptools\n",
    "import re\n",
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "import json\n",
    "from deep_translator import GoogleTranslator\n",
    "import urllib3\n",
    "from bs4 import BeautifulSoup\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b728e061",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "from collections import Counter\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n",
    "import wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ecc1d0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "links = [\n",
    "    '1983_United_States_embassy_bombing_in_Beirut',\n",
    "    '1982_Lebanon_War',\n",
    "    'Bachir_Gemayel',\n",
    "    'May_17_Agreement',\n",
    "    'Mountain_War_(Lebanon)',\n",
    "    'Palestinian_insurgency_in_South_Lebanon',\n",
    "    'Sabra_and_Shatila_massacre',\n",
    "    'Siege_of_Beirut'\n",
    "]\n",
    "\n",
    "dirs = [\n",
    "    'datasets_updated/1982-1984/1983_United_States_embassy_bombing_in_Beirut/',\n",
    "    'datasets_updated/1982-1984/1982_Lebanon_War/',\n",
    "    'datasets_updated/1982-1984/Bachir_Gemayel_Assasination/',\n",
    "    'datasets_updated/1982-1984/May_17_Agreement/',\n",
    "    'datasets_updated/1982-1984/Mountain_War_(Lebanon)/',\n",
    "    'datasets_updated/1982-1984/Palestinian_insurgency_in_South_Lebanon/',\n",
    "    'datasets_updated/1982-1984/Sabra_and_Shatila_massacre/',\n",
    "    'datasets_updated/1982-1984/Seige_of_Beirut/',\n",
    "]\n",
    "\n",
    "def mkdir(directory):\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "364af256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Siege_of_Beirut\n",
      "url:  https://en.wikipedia.org/wiki/Siege_of_Beirut\n",
      "title:  Siege of Beirut\n",
      "['Arab', 'Palestinian', 'Southern', 'Italian', 'Greek', 'American', 'Palestinians', 'Israelis', 'Tunis', 'Lebanese', 'French', 'Maronite', 'Syrian', 'Syrians', 'Maronites', 'pro-Lebanese', 'Israeli']\n",
      "['عرب', 'فلسطيني', 'الجنوب', 'إيطالي', 'اليونانية', 'أمريكي', 'فلسطينيون', 'الإسرائيليين', 'تونس', 'لبناني', 'فرنسي', 'موارنة', 'سوري', 'سوريون', 'الموارنة', 'الموالية للبنانيين', 'إسرائيلي']\n",
      "              en                  ar\n",
      "0           Arab                 عرب\n",
      "1    Palestinian             فلسطيني\n",
      "2       Southern              الجنوب\n",
      "3        Italian              إيطالي\n",
      "4          Greek           اليونانية\n",
      "5       American              أمريكي\n",
      "6   Palestinians           فلسطينيون\n",
      "7       Israelis        الإسرائيليين\n",
      "8          Tunis                تونس\n",
      "9       Lebanese              لبناني\n",
      "10        French               فرنسي\n",
      "11      Maronite              موارنة\n",
      "12        Syrian                سوري\n",
      "13       Syrians              سوريون\n",
      "14     Maronites            الموارنة\n",
      "15  pro-Lebanese  الموالية للبنانيين\n",
      "16       Israeli            إسرائيلي\n",
      "===========================================================================================\n"
     ]
    }
   ],
   "source": [
    "for i, p in enumerate(links):\n",
    "    print(p)\n",
    "    pw = wikipedia.page(p, auto_suggest=False)\n",
    "    print('url: ', pw.url)\n",
    "    print('title: ', pw.title)\n",
    "    # print('content: ', pw.content[:300])\n",
    "    doc = nlp(pw.content)\n",
    "    ethn_race = [(X.text, X.label_) for X in doc.ents if X.label_ == 'NORP']\n",
    "    ethn_race = list(set(ethn_race))\n",
    "    ethn_race_en = [er[0] for er in ethn_race]\n",
    "    ethn_race_ar = [GoogleTranslator(source='auto', target='ar').translate(er) for er in ethn_race_en]\n",
    "    print(ethn_race_en)\n",
    "    print(ethn_race_ar)\n",
    "    ethnicities_races = pd.DataFrame()\n",
    "    ethnicities_races['en'] = ethn_race_en\n",
    "    ethnicities_races['ar'] = ethn_race_ar\n",
    "    print(ethnicities_races)\n",
    "    mkdir(dirs[i])\n",
    "    ethnicities_races.to_csv(os.path.join(dirs[i], 'ethnicities_races.csv'), index=False, encoding='utf-8-sig')\n",
    "    print('===========================================================================================')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c42b85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
